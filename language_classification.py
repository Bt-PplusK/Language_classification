# -*- coding: utf-8 -*-
"""language_classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/136m0zcDvx8jnCeN7D29S3iYv7vIM78Rh
"""

from google.colab import drive
drive.mount('/content/drive')

pip install keras_preprocessing

import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from tensorflow import keras
from keras.models import Sequential
from keras_preprocessing.sequence import pad_sequences
from keras_preprocessing.text import Tokenizer
from keras.layers import Dense, BatchNormalization, Embedding, LSTM
from keras.metrics import Accuracy
from keras import utils
from keras import callbacks
from sklearn.model_selection import train_test_split
from absl import logging
logging.set_verbosity(logging.ERROR)

df = pd.read_csv('/content/drive/MyDrive/Dataset.csv')

df

df.head(10)

df.info()

df.shape

df.columns

import numpy as np
counts = df['Label'].value_counts()
labels = counts.index

plt.figure(figsize=(13, 8))
plt.pie(counts, labels=labels, autopct='%1.1f%%', colors=plt.cm.plasma(np.linspace(0, 1, len(labels))))
plt.title('Distribution of Labels')
plt.show()

languages_to_drop = ['en', 'ja', 'zh' , 'es', 'ko', 'sw']

df = df[~df['Label'].isin(languages_to_drop)]

df = df.reset_index(drop=True)

df

print(f'Number of objects in the dataset: {df.shape[0]}')

label_type = list(df['Label'].unique())
print(f'Types of labels in the dataset: {label_type}')

df.replace('my', 0, inplace=True)
df.replace('si', 1, inplace=True)
df.replace('ta', 2, inplace=True)
df['Label'] = df['Label'].astype('int8')

df

groups = df.groupby(by='Label').count().Data
CNT_my = groups[0]
CNT_si = groups[1]
CNT_ta = groups[2]
fig = go.Figure()
fig.add_trace(go.Bar(
    x=['my', 'si','ta'],
    y=[CNT_my, CNT_si , CNT_ta],
    marker_color='indianred',
    width=[0.4, 0.4]))

fig.update_layout(title='Classes and their number in the dataset', title_x=0.5)

texts = df['Data']
labels = df['Label']

texts.shape

NUM_WORDS = 30000
MAX_TEXT_LEN = 100

tokenizer = Tokenizer(num_words=NUM_WORDS)
tokenizer.fit_on_texts(texts)

word_count = 50
keys = list(tokenizer.word_index.keys())[:word_count]
values = list(tokenizer.word_index.values())[:word_count]
list(zip(keys, values))

sequences = tokenizer.texts_to_sequences(texts)

# As a result, the text under the following index was converted to a vector
index = 6
print(texts[index])
print(sequences[index])

X = pad_sequences(sequences, maxlen=MAX_TEXT_LEN)  # Standardization of the number of elements in a vector
y = labels.copy()

sequences_len = []
for sequence in sequences:
    seq_len = len(sequence)
    sequences_len.append(seq_len)

fig = go.Figure(data=[go.Histogram(x=sequences_len, marker_color='indianred')])
fig.update_layout(title='Histogram of the length of texts', title_x=0.5,xaxis_title="Text length",
                  yaxis_title="Count")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)
print(f'Training sample size: {len(X_train)}')
print(f'Test sample size: {len(X_test)}')

"""# Modeling"""

from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score , accuracy_score

#A recurrent neural network (RNN) model with an LSTM layer ()
import tensorflow as tf
from tensorflow.keras import layers
EMBEDDING_DIM = 100

model = tf.keras.Sequential([
    layers.Embedding(input_dim=NUM_WORDS, output_dim=EMBEDDING_DIM, input_length=MAX_TEXT_LEN),
    layers.LSTM(units=64),  # Or other RNN layers like GRU
    layers.Dense(units=3, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

'''#Naive Bayes classifier ML model
from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
model =model.fit(X_train, y_train)
y_pred = model.predict(X_test)

f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
accuracy = accuracy_score(y_test, y_pred)

print('Accuracy_score:', accuracy)
print('F1-score:', f1)
print('Recall_score:', recall)
print('Precision_score:', precision)'''

'''from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
accuracy = accuracy_score(y_test, y_pred)

print('Accuracy_score:', accuracy)
print('F1-score:', f1)
print('Recall_score:', recall)
print('Precision_score:', precision)'''

'''from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs')

lr_model.fit(X_train, y_train)
y_pred = lr_model.predict(X_test)

f1 = f1_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
accuracy = accuracy_score(y_test, y_pred)

print('Accuracy_score:', accuracy)
print('F1-score:', f1)
print('Recall_score:', recall)
print('Precision_score:', precision)'''

import matplotlib.pyplot as plt

# Create a visually striking and informative plot
plt.figure(figsize=(12, 6))  # Size adjusted for visual clarity
plt.style.use('seaborn-whitegrid')  # Apply a visual style for aesthetics

plt.plot(history.history['accuracy'], label='Training Accuracy', color='royalblue')  # Enhanced label clarity
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orangered')

plt.title('Model Performance Over Epochs', fontsize=16, fontweight='bold')  # Clear and concise title
plt.xlabel('Epochs', fontsize=14)
plt.ylabel('Accuracy', fontsize=14)

plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

plt.grid(True)
plt.legend(fontsize=12)

plt.tight_layout()  # Ensure optimal spacing for readability
plt.show()

print(f'Metric on test: {model.evaluate(X_test, y_test)}')
print(f'Metric on train: {model.evaluate(X_train, y_train)}')

model.summary()

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred,axis =1)
cm = confusion_matrix(y_test, y_pred_classes)
print(cm)

f1 = f1_score(y_test, y_pred_classes, average='weighted')
recall = recall_score(y_test, y_pred_classes, average='weighted')
precision = precision_score(y_test, y_pred_classes, average='weighted')
accuracy = accuracy_score(y_test, y_pred_classes)

print('Accuracy_score:', accuracy)
print('F1-score:', f1)
print('Recall_score:', recall)
print('Precision_score:', precision)

model.save('language_classification.h5')

Loaded_model = tf.keras.models.load_model('/content/language_classification.h5')

def ml_pipeline(text: str) -> str:
    """Model prediction function for three-languages prediction"""
    try:
        sequence = tokenizer.texts_to_sequences([text])
        sequence = pad_sequences(sequence, maxlen=MAX_TEXT_LEN)

        if sequence.max() == 0:
            return 'Enter texts of Burmese,Sinhala and Tamil'

        predict = Loaded_model.predict(sequence, verbose=0)  # Get class probabilities
        predicted_class = np.argmax(predict)  # Determine the most probable class

        if predicted_class == 0:
            return 'Burmese'  # Replace with your actual class labels
        elif predicted_class == 1:
            return 'Sinhala'
        else:
            return 'Tamil'

    except AttributeError:
        return 'Enter the text'

ml_pipeline('ဇီဝဗေဒ ပညာတွင် ဆင့်ကဲပြောင်းလဲမှုဖြစ်စဉ်')

ml_pipeline('අද්මිරාල්')

ml_pipeline('இக்கட்டுரை தமிழ் மொழி பற்றியது. ஏனைய பயன்பாடுகளுக்குத்')

ml_pipeline('How can you define Love?')

ml_pipeline('လေယာဉ်ပျံ')

ml_pipeline('ဒီမိုကရေစီ')